{"id":"chatboti-034","title":"Add get_embedding method to wrap embed_client and convert to ndarray","description":"Create method that calls embed_client.embed() and converts result to np.ndarray directly","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T12:50:04.675288+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:50:54.234447+11:00","closed_at":"2026-02-13T12:50:54.234447+11:00","close_reason":"Added get_embedding() method and used it in add_document() and search()"}
{"id":"chatboti-0y6","title":"Remove embed_client from constructor parameters","description":"Simplify GenericRAGService to only support high-level API (service_name, model). Remove low-level embed_client path.","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T12:44:47.900426+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:46:03.649435+11:00","closed_at":"2026-02-13T12:46:03.649435+11:00","close_reason":"Removed embed_client parameter and low-level API. Simplified to only support high-level API."}
{"id":"chatboti-2oz","title":"Phase 2: GenericRAGService with JSON storage","notes":"Implement GenericRAGService with FAISS vector index and JSON metadata storage:\n\n1. Constructor:\n   - index_path (FAISS), metadata_path (JSON)\n   - embedding_dim, embed_client parameters\n   - Load or create FAISS IndexFlatIP\n   - Load chunk_refs (List[ChunkRef]) and documents (Dict[str, Document])\n\n2. Core methods:\n   - add_document(doc) - add document chunks to FAISS\n   - build_embeddings_from_documents(source, doc_type) - load and embed\n   - save() - persist FAISS index and JSON metadata\n\n3. Storage wrapper methods (for cloud extensibility):\n   - _vector_search(query_emb, k) → (distances, faiss_ids)\n   - _get_chunk_refs(faiss_ids) → List[ChunkRef]\n   - _get_chunk_texts(refs) → Dict[ChunkRef, str] (optimized)\n   - _get_document_texts(doc_ids) → Dict[str, str]\n   - _save_metadata() - JSON serialization\n\n4. Search:\n   - async search(query, k, include_documents) → List[ChunkResult]\n   - Returns chunk text + optional full document text\n   - Uses wrapper methods for all storage access\n\n5. Document loader integration:\n   - _get_loader(source) - returns appropriate loader\n   - Initial support for CSV via CSVDocumentLoader\n\nStorage architecture:\n- FAISS index: vectors only (float32)\n- JSON metadata: chunk_refs array + documents dict\n- O(1) array access for chunk_refs (array index = faiss_id)\n- Good for \u003c1K documents","status":"closed","priority":1,"issue_type":"epic","owner":"apposite@gmail.com","created_at":"2026-02-13T10:41:32.103211+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:33:00.900899+11:00","closed_at":"2026-02-13T11:33:00.900899+11:00","close_reason":"Completed Phase 2: GenericRAGService with FAISS+JSON storage, all methods implemented and tested","dependencies":[{"issue_id":"chatboti-2oz","depends_on_id":"chatboti-yot","type":"blocks","created_at":"2026-02-13T10:41:54.253087+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2oz.1","title":"Implement GenericRAGService init and storage wrappers","description":"Implement GenericRAGService class with __init__, FAISS/JSON loading, and storage wrapper methods (_vector_search, _get_chunk_refs, _get_chunk_texts, _get_document_texts, _save_metadata)","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:26:43.961581+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:19:13.080456+11:00","closed_at":"2026-02-13T12:19:13.080456+11:00","close_reason":"Obsolete - replaced by 2oz.6 and 2oz.7","dependencies":[{"issue_id":"chatboti-2oz.1","depends_on_id":"chatboti-2oz","type":"parent-child","created_at":"2026-02-13T11:26:43.9624+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2oz.2","title":"Implement document management (add_document, save)","description":"Implement add_document() to add docs to FAISS, save() to persist, and _get_loader() for CSV support","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:26:44.113491+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:19:13.178955+11:00","closed_at":"2026-02-13T12:19:13.178955+11:00","close_reason":"Obsolete - replaced by 2oz.6 and 2oz.7","dependencies":[{"issue_id":"chatboti-2oz.2","depends_on_id":"chatboti-2oz","type":"parent-child","created_at":"2026-02-13T11:26:44.114242+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2oz.3","title":"Implement build_embeddings_from_documents","description":"Implement async build_embeddings_from_documents() that loads documents via loader and builds embeddings","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:26:44.265852+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:19:13.274153+11:00","closed_at":"2026-02-13T12:19:13.274153+11:00","close_reason":"Obsolete - replaced by 2oz.6 and 2oz.7","dependencies":[{"issue_id":"chatboti-2oz.3","depends_on_id":"chatboti-2oz","type":"parent-child","created_at":"2026-02-13T11:26:44.266589+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2oz.4","title":"Implement search method","description":"Implement async search() method with query embedding, FAISS search, and ChunkResult construction","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:26:44.418574+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:19:13.370593+11:00","closed_at":"2026-02-13T12:19:13.370593+11:00","close_reason":"Obsolete - replaced by 2oz.6 and 2oz.7","dependencies":[{"issue_id":"chatboti-2oz.4","depends_on_id":"chatboti-2oz","type":"parent-child","created_at":"2026-02-13T11:26:44.419339+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2oz.5","title":"Write tests for GenericRAGService","description":"Comprehensive tests for GenericRAGService including init, add_document, search, save/load","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:26:44.570476+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:19:13.464142+11:00","closed_at":"2026-02-13T12:19:13.464142+11:00","close_reason":"Obsolete - replaced by 2oz.6 and 2oz.7","dependencies":[{"issue_id":"chatboti-2oz.5","depends_on_id":"chatboti-2oz","type":"parent-child","created_at":"2026-02-13T11:26:44.57123+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2oz.6","title":"Implement GenericRAGService class","description":"Implement complete GenericRAGService in chatboti/generic_rag.py with all methods: __init__, storage wrappers, add_document, save, build_embeddings_from_documents, search","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:27:01.03688+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:28:32.028998+11:00","closed_at":"2026-02-13T11:28:32.028998+11:00","close_reason":"Implemented GenericRAGService with FAISS+JSON storage, search, and wrapper methods","dependencies":[{"issue_id":"chatboti-2oz.6","depends_on_id":"chatboti-2oz","type":"parent-child","created_at":"2026-02-13T11:27:01.037641+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2oz.7","title":"Write tests for GenericRAGService","description":"Write comprehensive tests in tests/test_generic_rag.py covering all GenericRAGService functionality","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:27:01.18933+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:32:34.645903+11:00","closed_at":"2026-02-13T11:32:34.645903+11:00","close_reason":"Comprehensive tests for GenericRAGService written and passing","dependencies":[{"issue_id":"chatboti-2oz.7","depends_on_id":"chatboti-2oz","type":"parent-child","created_at":"2026-02-13T11:27:01.1901+11:00","created_by":"Bosco Ho"},{"issue_id":"chatboti-2oz.7","depends_on_id":"chatboti-2oz.6","type":"blocks","created_at":"2026-02-13T11:27:07.178523+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-2p3","title":"Spec: Compare Parquet vs faiss-cpu for vector storage","description":"Evaluate and compare different vector storage options:\n1. Parquet for embeddings storage\n2. faiss-cpu for vector indexing\n3. Performance benchmarks (read/write, query speed)\n4. Storage efficiency and file sizes\n5. Integration complexity\n6. Recommend best approach for this use case","status":"closed","priority":2,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T15:48:13.240105+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T15:56:40.883262+11:00","closed_at":"2026-02-12T15:56:40.883262+11:00","close_reason":"Completed comparison of vector storage options"}
{"id":"chatboti-2qy","title":"Create end-to-end integration test","description":"Write test that loads sample CSV, builds embeddings, searches, and verifies results work end-to-end with a real embed client (or mock). Verifies the full pipeline actually runs.","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:40:26.01813+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:51:50.140585+11:00","closed_at":"2026-02-13T11:51:50.140585+11:00","close_reason":"Created comprehensive E2E test covering CSV load, embedding generation, search, and persistence. Also fixed bug in generic_rag.py to handle empty index searches gracefully.","dependencies":[{"issue_id":"chatboti-2qy","depends_on_id":"chatboti-owm","type":"blocks","created_at":"2026-02-13T11:40:33.074552+11:00","created_by":"Bosco Ho"},{"issue_id":"chatboti-2qy","depends_on_id":"chatboti-aof","type":"blocks","created_at":"2026-02-13T11:40:33.217086+11:00","created_by":"Bosco Ho"},{"issue_id":"chatboti-2qy","depends_on_id":"chatboti-5kc","type":"blocks","created_at":"2026-02-13T11:40:33.36188+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-3q1","title":"Update mcp_server.py to use GenericRAGService","description":"Adapt speaker-specific MCP tools to work with GenericRAGService instead of old RAGService","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T12:25:45.926103+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:27:02.990955+11:00","closed_at":"2026-02-13T12:27:02.990955+11:00","close_reason":"Successfully updated mcp_server.py to use GenericRAGService with model-specific paths"}
{"id":"chatboti-5kc","title":"Fix async/sync mismatch in document loaders","description":"Either make CSVDocumentLoader.load() async or remove await from build_embeddings_from_documents() line 85. Decision: if loaders need I/O (future: fetch from URL), make them async; otherwise keep sync and fix caller.","status":"closed","priority":0,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:40:25.877727+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:43:08.30942+11:00","closed_at":"2026-02-13T11:43:08.30942+11:00","close_reason":"Made DocumentLoader.load() async to fix mismatch and enable future URL-based loaders"}
{"id":"chatboti-68k","title":"Spec: Refactor to generic document storage independent of speaker structure","description":"Design a generic JSON data structure for storing embeddings that is agnostic to the current speaker/agenda domain. The system should work with any document type without hardcoded knowledge of speaker fields (name, bio, abstract, etc.).\n\nGoals:\n1. Define generic document model (id, content, metadata, embeddings)\n2. Separate domain-specific logic from core RAG functionality\n3. Support arbitrary document types and schemas\n4. Maintain backwards compatibility or provide migration path\n5. Consider how this relates to the metadata storage design (chatboti-in9)\n\nDeliverable: Specification document outlining:\n- Current coupling to speaker structure\n- Proposed generic document model\n- API/interface changes needed\n- Migration strategy from current speaker-centric data\n- Integration with metadata storage design","status":"closed","priority":2,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T16:09:56.283331+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T16:18:34.841118+11:00","closed_at":"2026-02-12T16:18:34.841118+11:00","close_reason":"Completed generic document storage specification"}
{"id":"chatboti-6r7","title":"Refactor: Move embeddings generation to CLI command instead of constructor","description":"Move embedding generation out of the constructor to a separate CLI command. This will:\n1. Improve startup time by not generating embeddings on every initialization\n2. Allow users to explicitly generate/update embeddings when needed\n3. Separate concerns between initialization and embedding computation","status":"closed","priority":2,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T15:47:49.407118+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T15:55:32.674281+11:00","closed_at":"2026-02-12T15:55:32.674281+11:00","close_reason":"Refactored embeddings generation to separate CLI command"}
{"id":"chatboti-9w2","title":"Merge multi-model support into main spec document","description":"Integrate MULTI-MODEL-SUPPORT.md content into docs/generic-document-storage-spec.md.\n\nInstead of a separate document, add a comprehensive section on multi-model support directly in the main spec.\n\nGoals:\n1. Add new section 'Multi-Model Support' to generic-document-storage-spec.md\n2. Include model configuration, dynamic dimensions, storage strategy\n3. Add performance comparison table by model dimensions\n4. Include migration utilities and examples\n5. Update implementation phases to mention model flexibility\n6. Archive or delete MULTI-MODEL-SUPPORT.md after merging\n\nThe spec should show how the architecture handles any embedding model (384 to 3072 dims) without separate versions.","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T17:08:15.665553+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T17:11:27.920059+11:00","closed_at":"2026-02-12T17:11:27.920059+11:00","close_reason":"Merged multi-model support into main specification"}
{"id":"chatboti-aof","title":"Enable embedding generation in add_document()","description":"Uncomment and fix lines 61-62 in generic_rag.py to actually generate embeddings and add to FAISS index. Make add_document() async if needed. Use self.embed_client.embed() to get embedding vector.","status":"closed","priority":0,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:40:25.739918+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:48:35.003769+11:00","closed_at":"2026-02-13T11:48:35.003769+11:00","close_reason":"Enabled embedding generation using EmbedClient, made add_document async","dependencies":[{"issue_id":"chatboti-aof","depends_on_id":"chatboti-owm","type":"blocks","created_at":"2026-02-13T11:40:32.934341+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-bx9","title":"Consolidate all planning documents into unified specs","description":"Merge and consolidate overlapping planning documents into a cohesive documentation set.\n\nCurrent documents:\n1. PLAN-SUMMARY.md - Quick reference (keep as-is)\n2. STORAGE-EVOLUTION.md - JSON → SQLite strategy\n3. docs/generic-document-storage-spec.md - Main spec\n4. docs/faiss-multiple-documents-spec.md - FAISS details\n5. docs/metadata-storage-design.md - Metadata design\n6. docs/vector-storage-comparison.md - Storage comparison\n\nGoals:\n1. Merge STORAGE-EVOLUTION.md into generic-document-storage-spec.md\n2. Consolidate faiss-multiple-documents-spec.md into generic-document-storage-spec.md\n3. Update generic-document-storage-spec.md to be THE comprehensive reference\n4. Keep PLAN-SUMMARY.md as quick 1-page reference\n5. Archive or remove redundant docs\n6. Ensure no information is lost\n\nFinal structure:\n- PLAN-SUMMARY.md (1 page quick ref)\n- docs/generic-document-storage-spec.md (comprehensive spec with everything)\n- docs/analysis/ (archived detailed analysis)\n\nDeliverable:\n- Single comprehensive spec with all implementation details\n- Clean, non-redundant documentation structure","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T16:59:53.33932+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T17:03:34.941829+11:00","closed_at":"2026-02-12T17:03:34.941829+11:00","close_reason":"Consolidated all plans into unified documentation"}
{"id":"chatboti-cb8","title":"Refactor GenericRAGService with factory method and lifecycle management","description":"Add make_model_slug, detect_embedding_dim, from_service factory method, and async context manager support to GenericRAGService. Update server.py, mcp_server.py, and rag_cli.py to use simplified API.","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T12:32:35.891777+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:35:41.731925+11:00","closed_at":"2026-02-13T12:35:41.731925+11:00","close_reason":"Successfully added factory method and async context manager to GenericRAGService. Simplified API across server.py, mcp_server.py, and rag_cli.py"}
{"id":"chatboti-d23","title":"Convert make_model_slug and detect_embedding_dim to instance methods","description":"Change from @staticmethod to regular instance methods using self","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T12:47:15.587312+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:47:51.836356+11:00","closed_at":"2026-02-13T12:47:51.836356+11:00","close_reason":"Converted make_model_slug and detect_embedding_dim to instance methods"}
{"id":"chatboti-dna","title":"JSON to SQLite migration utility","notes":"Implement migration utility to convert from JSON to SQLite storage:\n\n1. CLI command:\n   - chatboti migrate-to-sqlite --json=metadata.json --db=metadata.db\n   - Progress reporting\n   - Validation checks\n\n2. Migration process:\n   - Load JSON metadata (chunk_refs, documents)\n   - Create SQLite schema\n   - Batch insert chunk_refs with FAISS IDs\n   - Batch insert documents with JSON serialization\n   - Copy FAISS index (no changes needed)\n   - Verify data integrity\n\n3. Validation:\n   - Count checks (same number of chunks/documents)\n   - Sample verification (random chunk lookups)\n   - Search consistency tests\n\n4. Rollback support:\n   - Keep original JSON backup\n   - Transaction-based migration\n   - Atomic operation\n\n5. Performance:\n   - Batch inserts for efficiency\n   - Progress updates for large datasets\n   - Estimated time remaining\n\n6. Use cases:\n   - When JSON dataset grows \u003e1K documents\n   - When query performance degrades\n   - When ACID guarantees needed","status":"open","priority":2,"issue_type":"feature","owner":"apposite@gmail.com","created_at":"2026-02-13T10:42:51.815033+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:03:46.540727+11:00","dependencies":[{"issue_id":"chatboti-dna","depends_on_id":"chatboti-2oz","type":"blocks","created_at":"2026-02-13T10:42:58.316155+11:00","created_by":"Bosco Ho"},{"issue_id":"chatboti-dna","depends_on_id":"chatboti-l87","type":"blocks","created_at":"2026-02-13T10:42:58.45807+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-dxz","title":"Spec: Merge embedding storage analysis into generic document storage spec","description":"Integrate the insights from embedding-storage-architecture.md and faiss-vs-numpy-size-comparison.md into docs/generic-document-storage-spec.md.\n\nGoals:\n1. Update Section 3 (Proposed Architecture) to recommend FAISS as primary vector storage\n2. Add Section 2.5 (Storage Format Comparison) with analysis from embedding-storage-architecture.md\n3. Update Section 5 (Integration Points) to include FAISS sizing data\n4. Add performance benchmarks and memory comparisons\n5. Update API examples to show FAISS usage\n6. Keep all existing good content from the original spec\n7. Remove/consolidate redundant sections\n\nKey points to integrate:\n- FAISS is smaller than NumPy (+15 MB vs +300 MB for ChromaDB)\n- FAISS as primary vector storage (not Parquet/SQLite BLOB)\n- Never use List[float] anywhere\n- Always use ndarray[float32]\n- Memory efficiency: 8x better than Python lists\n- Performance: 10-100x faster with FAISS indexing\n- Architecture: FAISS for vectors + SQLite for metadata\n\nDeliverable:\n- Single comprehensive spec: docs/generic-document-storage-spec.md (updated)\n- Archive old analysis docs or delete them after merging","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T16:46:02.964489+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T16:51:09.618535+11:00","closed_at":"2026-02-12T16:51:09.618535+11:00","close_reason":"Merged all embedding storage analysis into comprehensive generic document storage spec. Added FAISS recommendation, storage format comparison, package size analysis, and updated architecture throughout."}
{"id":"chatboti-f38","title":"Refactor GenericRAGService to use constructor + context manager pattern","description":"Move async initialization from factory method into __aenter__. Constructor should just store parameters.","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T12:39:20.060629+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:41:18.495759+11:00","closed_at":"2026-02-13T12:41:18.495759+11:00","close_reason":"Successfully refactored to use constructor + context manager pattern. Much cleaner API!"}
{"id":"chatboti-in9","title":"Spec: Design metadata storage for RAG system","description":"Design metadata storage architecture for RAG pipeline:\n1. Document source tracking (file path, URL, timestamp, etc.)\n2. Embedding index mapping (vector ID to document/chunk)\n3. Chunked text storage (full text vs references)\n4. Return text index for retrieval results\n5. Compare storage approaches (SQLite, JSON, Parquet, separate files)\n6. Query patterns and access efficiency\n7. Recommend optimal metadata storage strategy","status":"closed","priority":2,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T15:48:44.842146+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T15:56:58.901958+11:00","closed_at":"2026-02-12T15:56:58.901958+11:00","close_reason":"Completed metadata storage design"}
{"id":"chatboti-l87","title":"Phase 3: SQLiteRAGService for scale","notes":"Implement SQLiteRAGService as subclass of GenericRAGService for \u003e1K documents:\n\n1. Constructor:\n   - index_path (FAISS), db_path (SQLite)\n   - Connect to SQLite database\n   - Create tables if new database\n\n2. Schema:\n   - chunk_refs table: (faiss_id PRIMARY KEY, document_id, chunk_key)\n   - documents table: (id PRIMARY KEY, content, full_text, metadata)\n   - CRITICAL: faiss_id must be PRIMARY KEY for O(log n) lookups\n\n3. Override storage wrappers:\n   - _get_chunk_refs(faiss_ids) - fetch from SQLite with IN query\n   - _get_document_texts(doc_ids) - SELECT id, full_text, content\n   - _get_documents(doc_ids) - full Document objects (for non-search ops)\n   - _save_metadata() - commit SQLite transaction\n\n4. Performance:\n   - B-tree indexed lookups: O(k log n) for k results\n   - ~1ms for k=10 results vs 0.1ms for JSON\n   - Better for \u003e1K documents with ACID transactions\n   - Efficient queries with prepared statements\n\n5. Compatibility:\n   - Same API as GenericRAGService\n   - Drop-in replacement via storage wrapper pattern\n   - Search method inherited, no changes needed","status":"open","priority":2,"issue_type":"epic","owner":"apposite@gmail.com","created_at":"2026-02-13T10:41:33.818462+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:02:38.036692+11:00","dependencies":[{"issue_id":"chatboti-l87","depends_on_id":"chatboti-2oz","type":"blocks","created_at":"2026-02-13T10:41:54.395473+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-owm","title":"Create embed client wrapper for GenericRAGService","description":"Create chatboti/embed_client.py with abstract EmbedClient base class and concrete implementations (OpenAIEmbedClient, OllamaEmbedClient) that wrap microeval.llm.get_llm_client() or implement directly. Must have async embed(text: str) -\u003e List[float] method.","status":"closed","priority":0,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:40:25.604458+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:44:13.655438+11:00","closed_at":"2026-02-13T11:44:13.655438+11:00","close_reason":"Implemented EmbedClient base class with OpenAI/Ollama/Microeval wrappers. All 21 tests passing."}
{"id":"chatboti-qcw","title":"Remove args from make_model_slug and detect_embedding_dim","description":"Use self.model and self.embed_client instead of passing as args","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T12:49:03.759907+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T12:49:34.250024+11:00","closed_at":"2026-02-13T12:49:34.250024+11:00","close_reason":"Removed arguments from make_model_slug and detect_embedding_dim. Now use self.model and self.embed_client"}
{"id":"chatboti-qlp","title":"Spec: Replace JSON embeddings with faiss-cpu and support multiple documents for RAG","description":"Design and document approach for:\n1. Using faiss-cpu for vector storage instead of JSON serialization\n2. Supporting multiple documents in RAG pipeline\n3. Document indexing, retrieval, and management strategies\n4. Performance and scalability considerations","status":"closed","priority":2,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T15:47:46.48506+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T16:18:54.396431+11:00","closed_at":"2026-02-12T16:18:54.396431+11:00","close_reason":"Completed comprehensive specification covering FAISS integration, multiple document support, chunking strategies, metadata storage integration, API design, performance targets, and 10-phase implementation roadmap"}
{"id":"chatboti-qnc","title":"Phase 4: SpeakerRAGService backwards compatibility","notes":"Implement SpeakerRAGService as backwards-compatible wrapper:\n\n1. Purpose:\n   - Maintain existing speaker-specific API\n   - Zero breaking changes for current users\n   - Wrap GenericRAGService with domain-specific convenience\n\n2. Implementation:\n   - Inherit from GenericRAGService\n   - Add speaker-specific methods if needed\n   - Pre-configure for speakers.csv structure\n   - Default embed_fields: ['bio', 'abstract']\n\n3. Legacy API mapping:\n   from chatboti.rag import RAGService  # Old import\n   rag = RAGService()                    # Works unchanged\n   \n4. Internal changes:\n   - Replace old speaker-centric storage with GenericRAGService\n   - Migrate data format if needed\n   - Maintain same search results format\n\n5. Migration support:\n   - Detect old data format\n   - Auto-convert to new format on first load\n   - Preserve all existing functionality\n   - Document migration process\n\nGoal: Existing code continues to work without changes while gaining new generic capabilities internally.","status":"open","priority":2,"issue_type":"epic","owner":"apposite@gmail.com","created_at":"2026-02-13T10:41:35.20384+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:02:51.356086+11:00","dependencies":[{"issue_id":"chatboti-qnc","depends_on_id":"chatboti-2oz","type":"blocks","created_at":"2026-02-13T10:41:54.534801+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-vzl","title":"Phase 5: Document loaders (CSV, JSON, PDF)","notes":"Implement additional document loaders beyond CSVDocumentLoader:\n\n1. JSONDocumentLoader:\n   - Load JSON documents with flexible schema\n   - Support both single doc and array of docs\n   - Configurable field mappings for id, content, metadata\n   - Auto-detect structure\n\n2. PDFDocumentLoader:\n   - Extract text from PDF files\n   - Chunking strategies (fixed size, semantic, paragraph)\n   - Metadata extraction (title, author, page numbers)\n   - Handle multi-page documents\n   - Chunk-level embeddings with i_start/i_end indices\n\n3. MarkdownDocumentLoader:\n   - Parse markdown with headers as chunk boundaries\n   - Preserve document structure\n   - Code blocks handling\n\n4. WebDocumentLoader:\n   - Fetch content from URLs\n   - HTML to text conversion\n   - Metadata from meta tags\n\n5. Chunking strategies:\n   - Fixed-size chunking (with overlap)\n   - Semantic chunking (sentence/paragraph boundaries)\n   - Recursive chunking for large documents\n   - Configurable chunk size and overlap\n\n6. Loader registry:\n   - Auto-detect loader by file extension\n   - _get_loader() method enhancement\n   - Pluggable loader architecture","status":"open","priority":3,"issue_type":"epic","owner":"apposite@gmail.com","created_at":"2026-02-13T10:41:36.848233+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:03:04.184409+11:00"}
{"id":"chatboti-w6u","title":"Refactor: Convert List[float] to np.ndarray[float32] throughout codebase","description":"Refactor all Python code to use NumPy float32 arrays instead of List[float] for embeddings and vector operations.\n\nGoals:\n1. Find all usages of List[float] in type hints and code\n2. Replace with np.ndarray (dtype=float32)\n3. Update function signatures and type hints\n4. Ensure all embedding operations use NumPy arrays\n5. Update serialization/deserialization to use .npy or binary formats\n6. Maintain backwards compatibility where needed\n\nBenefits:\n- 4-6x memory reduction (see memory-efficiency-analysis.md)\n- 100x faster vector operations with NumPy SIMD\n- Cache-friendly contiguous memory layout\n- Better integration with FAISS (uses float32 internally)\n\nFiles likely affected:\n- chatboti/rag.py (embedding storage and operations)\n- Any utility functions handling embeddings\n- Serialization/deserialization code\n\nTesting:\n- Verify cosine distance calculations produce same results\n- Check memory usage before/after\n- Ensure serialization works correctly","status":"closed","priority":2,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-12T16:27:29.633278+11:00","created_by":"Bosco Ho","updated_at":"2026-02-12T16:30:26.921265+11:00","closed_at":"2026-02-12T16:30:26.921265+11:00","close_reason":"Completed refactoring to np.ndarray[float32] with full backwards compatibility and testing"}
{"id":"chatboti-ycg","title":"Phase 6: Multi-model embedding support","notes":"Implement support for multiple embedding models with different dimensions:\n\n1. Model-specific storage:\n   - Separate FAISS index per model\n   - Pattern: vectors_{model_name}.faiss, metadata_{model_name}.json\n   - Support 384-3072 dimensions\n   - Examples:\n     * all-MiniLM-L6-v2: 384 dims, 1.5 MB/1K docs, 0.5ms\n     * nomic-embed-text: 768 dims, 3.0 MB/1K docs, 1.0ms\n     * text-embedding-3-small: 1536 dims, 6.0 MB/1K docs, 2.0ms\n     * text-embedding-3-large: 3072 dims, 12.0 MB/1K docs, 4.0ms\n\n2. Dynamic dimension handling:\n   - Detect embedding_dim from embed_client\n   - Create appropriate FAISS index size\n   - Validate dimensions on load\n\n3. Model configuration:\n   - Store model name in metadata\n   - Version tracking\n   - Model compatibility checks\n\n4. Migration utilities:\n   - Convert between models\n   - Re-embed with different model\n   - Batch conversion scripts\n\n5. Benefits:\n   - Cost optimization (smaller models for simple use cases)\n   - Performance tuning (faster vs more accurate)\n   - Future-proof architecture\n   - No code changes needed per model","status":"open","priority":3,"issue_type":"epic","owner":"apposite@gmail.com","created_at":"2026-02-13T10:41:38.535148+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:03:19.871806+11:00"}
{"id":"chatboti-yot","title":"Phase 1: Core abstractions","notes":"Implement core data structures for generic document storage:\n\n1. Document class with:\n   - id, content (dict), full_text (str), metadata (dict)\n   - chunks: Dict[str, DocumentChunk]\n   - get_chunk_text(key) method\n   - get_chunk_with_context(key, context_chars) method\n   - to_dict() and from_dict() serialization\n\n2. DocumentChunk dataclass with:\n   - faiss_id (int)\n   - i_start, i_end (Optional[int]) for text indices\n   - Supports both field-level (CSV) and chunk-level (PDF) embeddings\n\n3. ChunkRef dataclass:\n   - Maps faiss_id to (document_id, chunk_key)\n\n4. ChunkResult dataclass:\n   - document_id, chunk_key, text, document_text (optional)\n\n5. DocumentLoader base class:\n   - Abstract load() method\n\n6. CSVDocumentLoader implementation:\n   - Field-level embeddings from CSV rows\n   - embed_fields parameter for selective embedding\n\nKey design principles:\n- Text stored once per document (no duplication)\n- Chunks reference text via field name or (i_start, i_end) indices\n- 30x storage reduction for chunked documents\n- Type safety with ndarray[float32]\n- Sphinx-style docstrings","status":"closed","priority":1,"issue_type":"epic","owner":"apposite@gmail.com","created_at":"2026-02-13T10:41:30.752358+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:26:07.589287+11:00","closed_at":"2026-02-13T11:26:07.589287+11:00","close_reason":"Completed all subtasks: core data structures, loaders, and comprehensive tests"}
{"id":"chatboti-yot.1","title":"Implement core data structures (document.py)","notes":"Implement chatboti/document.py with core data structures:\n- Document class (id, content, full_text, metadata, chunks dict)\n- get_chunk_text(key) and get_chunk_with_context(key, context_chars) methods  \n- to_dict() and from_dict() serialization\n- DocumentChunk dataclass (faiss_id, i_start, i_end)\n- ChunkRef dataclass (document_id, chunk_key)\n- ChunkResult dataclass (document_id, chunk_key, text, document_text)\nUse Sphinx docstrings, type hints, dataclass decorator","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:15:13.556294+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:20:11.310375+11:00","closed_at":"2026-02-13T11:20:11.310375+11:00","close_reason":"Implemented Document, DocumentChunk, ChunkRef, ChunkResult with serialization","dependencies":[{"issue_id":"chatboti-yot.1","depends_on_id":"chatboti-yot","type":"parent-child","created_at":"2026-02-13T11:15:13.557459+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-yot.2","title":"Implement document loaders (loaders.py)","description":"Implement chatboti/loaders.py with DocumentLoader base class and CSVDocumentLoader. Loads CSV rows as Documents with field-level embeddings. Use Sphinx docstrings.","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:15:25.924302+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:21:17.828647+11:00","closed_at":"2026-02-13T11:21:17.828647+11:00","close_reason":"Implemented DocumentLoader base class and CSVDocumentLoader","dependencies":[{"issue_id":"chatboti-yot.2","depends_on_id":"chatboti-yot","type":"parent-child","created_at":"2026-02-13T11:15:25.925207+11:00","created_by":"Bosco Ho"},{"issue_id":"chatboti-yot.2","depends_on_id":"chatboti-yot.1","type":"blocks","created_at":"2026-02-13T11:15:26.08411+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-yot.3","title":"Write tests for document.py","description":"Write tests/test_document.py with unit tests for Document class, get_chunk_text, get_chunk_with_context, serialization, and all dataclasses","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:15:31.691625+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:22:59.966837+11:00","closed_at":"2026-02-13T11:22:59.966837+11:00","close_reason":"Comprehensive tests for Document class and dataclasses - all 22 tests passing","dependencies":[{"issue_id":"chatboti-yot.3","depends_on_id":"chatboti-yot","type":"parent-child","created_at":"2026-02-13T11:15:31.692425+11:00","created_by":"Bosco Ho"},{"issue_id":"chatboti-yot.3","depends_on_id":"chatboti-yot.1","type":"blocks","created_at":"2026-02-13T11:15:31.840185+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-yot.4","title":"Write tests for loaders.py","description":"Write tests/test_loaders.py with unit tests for CSVDocumentLoader including sample CSV file","status":"closed","priority":1,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T11:15:36.420141+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:25:32.75128+11:00","closed_at":"2026-02-13T11:25:32.75128+11:00","close_reason":"Comprehensive tests for CSVDocumentLoader with sample CSV fixture. All 14 tests passing including DocumentLoader base class, field-level chunking, get_chunk_text() integration, and edge cases.","dependencies":[{"issue_id":"chatboti-yot.4","depends_on_id":"chatboti-yot","type":"parent-child","created_at":"2026-02-13T11:15:36.420988+11:00","created_by":"Bosco Ho"},{"issue_id":"chatboti-yot.4","depends_on_id":"chatboti-yot.2","type":"blocks","created_at":"2026-02-13T11:15:36.567615+11:00","created_by":"Bosco Ho"}]}
{"id":"chatboti-ytx","title":"Phase 7: Documentation and migration guide","notes":"Create comprehensive documentation for generic document storage system:\n\n1. User guide:\n   - Getting started with GenericRAGService\n   - Loading documents from different sources\n   - Configuring embedding clients\n   - Search API usage\n   - When to use JSON vs SQLite storage\n\n2. Migration guide:\n   - Upgrading from speaker-specific to generic API\n   - Data format migration\n   - Code examples (before/after)\n   - Backwards compatibility notes\n\n3. API reference:\n   - All classes and methods (Sphinx autodoc)\n   - Document, DocumentChunk, ChunkRef, ChunkResult\n   - GenericRAGService, SQLiteRAGService, SpeakerRAGService\n   - DocumentLoader hierarchy\n\n4. Architecture documentation:\n   - Three-layer storage architecture\n   - FAISS + metadata design\n   - Storage wrapper pattern for extensibility\n   - Performance characteristics\n\n5. Examples:\n   - CSV field-level embeddings (speakers)\n   - PDF chunk-level embeddings\n   - Multi-model usage\n   - Custom document loaders\n\n6. Performance guide:\n   - Benchmarks and comparisons\n   - When to migrate to SQLite\n   - Optimization tips","status":"open","priority":4,"issue_type":"task","owner":"apposite@gmail.com","created_at":"2026-02-13T10:41:46.787409+11:00","created_by":"Bosco Ho","updated_at":"2026-02-13T11:03:32.75561+11:00"}
